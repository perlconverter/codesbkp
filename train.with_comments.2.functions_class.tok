def forwards ( self , orm ) : NEW_LINE # ▁ Adding ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . create_table ( ' student _ testcenteruser ' , ( ( ' id ' , self . gf ( ' django . db . models . fields . AutoField ' ) ( primary_key = True ) ) , ( ' user ' , self . gf ( ' django . db . models . fields . related . ForeignKey ' ) ( default = None , to = orm [ ' auth . User ' ] , unique = True ) ) , ( ' created _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now_add = True , db_index = True , blank = True ) ) , ( ' updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( auto_now = True , db_index = True , blank = True ) ) , ( ' user _ updated _ at ' , self . gf ( ' django . db . models . fields . DateTimeField ' ) ( db_index = True ) ) , ( ' candidate _ id ' , self . gf ( ' django . db . models . fields . IntegerField ' ) ( null = True , db_index = True ) ) , ( ' client _ candidate _ id ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' first _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , db_index = True ) ) , ( ' last _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , db_index = True ) ) , ( ' middle _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 30 , blank = True ) ) , ( ' suffix ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 255 , blank = True ) ) , ( ' salutation ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ( ' address _ 1' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 ) ) , ( ' address _ 2' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' address _ 3' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 40 , blank = True ) ) , ( ' city ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 32 , db_index = True ) ) , ( ' state ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 20 , blank = True ) ) , ( ' postal _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 16 , blank = True ) ) , ( ' country ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' phone ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 ) ) , ( ' extension ' , self . gf ( ' django . db . models . fields . CharField ' ) ( db_index = True , max_length = 8 , blank = True ) ) , ( ' phone _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , db_index = True ) ) , ( ' fax ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 35 , blank = True ) ) , ( ' fax _ country _ code ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 3 , blank = True ) ) , ( ' company _ name ' , self . gf ( ' django . db . models . fields . CharField ' ) ( max_length = 50 , blank = True ) ) , ) ) NEW_LINE db . send_create_signal ( ' student ' , [ ' TestCenterUser ' ] ) NEW_LINE DEDENT
def backwards ( self , orm ) : NEW_LINE # ▁ Deleting ▁ model ▁ ' TestCenterUser ' ENDCOM INDENT db . delete_table ( ' student _ testcenteruser ' ) NEW_LINE DEDENT
def validate_rule ( self , rule , rule_type = None ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Apply ▁ defaults ▁ to ▁ a ▁ rule ▁ dictionary ▁ and ▁ check ▁ that ▁ all ▁ values ▁ are ▁ valid . STRNEWLINE STRNEWLINE ▁ : param ▁ rule : ▁ rule ▁ dict STRNEWLINE ▁ : param ▁ rule _ type : ▁ Set ▁ to ▁ ' default ' ▁ if ▁ the ▁ rule ▁ is ▁ part ▁ of ▁ the ▁ default ▁ set ▁ of ▁ rules . STRNEWLINE ▁ : return : ▁ None STRNEWLINE ▁ ''' NEW_LINE priority = rule . get ( ' priority ' , 0 ) NEW_LINE if rule_type != ' default ' and ( priority < 100 or priority > 4096 ) : NEW_LINE INDENT raise Exception ( " Rule ▁ priority ▁ must ▁ be ▁ between ▁ 100 ▁ and ▁ 4096" ) NEW_LINE DEDENT def check_plural ( src , dest ) : NEW_LINE INDENT if isinstance ( rule . get ( src ) , list ) : NEW_LINE INDENT rule [ dest ] = rule [ src ] NEW_LINE rule [ src ] = None NEW_LINE DEDENT DEDENT check_plural ( ' destination _ address _ prefix ' , ' destination _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ address _ prefix ' , ' source _ address _ prefixes ' ) NEW_LINE check_plural ( ' source _ port _ range ' , ' source _ port _ ranges ' ) NEW_LINE check_plural ( ' destination _ port _ range ' , ' destination _ port _ ranges ' ) NEW_LINE DEDENT
def create_rule_instance ( self , rule ) : NEW_LINE INDENT ''' STRNEWLINE ▁ Create ▁ an ▁ instance ▁ of ▁ SecurityRule ▁ from ▁ a ▁ dict . STRNEWLINE STRNEWLINE ▁ : param ▁ rule : ▁ dict STRNEWLINE ▁ : return : ▁ SecurityRule STRNEWLINE ▁ ''' NEW_LINE return self . nsg_models . SecurityRule ( description = rule . get ( ' description ' , None ) , protocol = rule . get ( ' protocol ' , None ) , source_port_range = rule . get ( ' source _ port _ range ' , None ) , destination_port_range = rule . get ( ' destination _ port _ range ' , None ) , source_address_prefix = rule . get ( ' source _ address _ prefix ' , None ) , source_address_prefixes = rule . get ( ' source _ address _ prefixes ' , None ) , destination_address_prefix = rule . get ( ' destination _ address _ prefix ' , None ) , destination_address_prefixes = rule . get ( ' destination _ address _ prefixes ' , None ) , source_port_ranges = rule . get ( ' source _ port _ ranges ' , None ) , destination_port_ranges = rule . get ( ' destination _ port _ ranges ' , None ) , access = rule . get ( ' access ' , None ) , priority = rule . get ( ' priority ' , None ) , direction = rule . get ( ' direction ' , None ) , provisioning_state = rule . get ( ' provisioning _ state ' , None ) , name = rule . get ( ' name ' , None ) , etag = rule . get ( ' etag ' , None ) ) NEW_LINE DEDENT
def __init__ ( self ) : NEW_LINE INDENT self . module_arg_spec = dict ( default_rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , location = dict ( type = ' str ' ) , name = dict ( type = ' str ' , required = True ) , purge_default_rules = dict ( type = ' bool ' , default = False ) , purge_rules = dict ( type = ' bool ' , default = False ) , resource_group = dict ( required = True , type = ' str ' ) , rules = dict ( type = ' list ' , elements = ' dict ' , options = rule_spec ) , state = dict ( type = ' str ' , default = ' present ' , choices = [ ' present ' , ' absent ' ] ) , ) NEW_LINE self . default_rules = None NEW_LINE self . location = None NEW_LINE self . name = None NEW_LINE self . purge_default_rules = None NEW_LINE self . purge_rules = None NEW_LINE self . resource_group = None NEW_LINE self . rules = None NEW_LINE self . state = None NEW_LINE self . tags = None NEW_LINE self . nsg_models = None # ▁ type : ▁ azure . mgmt . network . models ENDCOM NEW_LINE self . results = dict ( changed = False , state = dict ( ) ) NEW_LINE super ( AzureRMSecurityGroup , self ) . __init__ ( self . module_arg_spec , supports_check_mode = True ) NEW_LINE DEDENT
def create_or_update ( self , results ) : NEW_LINE INDENT parameters = self . nsg_models . NetworkSecurityGroup ( ) NEW_LINE if results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules = [ ] NEW_LINE for rule in results . get ( ' rules ' ) : NEW_LINE INDENT parameters . security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT if results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules = [ ] NEW_LINE for rule in results . get ( ' default _ rules ' ) : NEW_LINE INDENT parameters . default_security_rules . append ( create_rule_instance ( self , rule ) ) NEW_LINE DEDENT DEDENT parameters . tags = results . get ( ' tags ' ) NEW_LINE parameters . location = results . get ( ' location ' ) NEW_LINE try : NEW_LINE INDENT poller = self . network_client . network_security_groups . create_or_update ( resource_group_name = self . resource_group , network_security_group_name = self . name , parameters = parameters ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT self . fail ( " Error ▁ creating / updating ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return create_network_security_group_dict ( result ) NEW_LINE DEDENT
def delete ( self ) : NEW_LINE INDENT try : NEW_LINE INDENT poller = self . network_client . network_security_groups . delete ( resource_group_name = self . resource_group , network_security_group_name = self . name ) NEW_LINE result = self . get_poller_result ( poller ) NEW_LINE DEDENT except CloudError as exc : NEW_LINE INDENT raise Exception ( " Error ▁ deleting ▁ security ▁ group ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . name , str ( exc ) ) ) NEW_LINE DEDENT return result NEW_LINE DEDENT
def __init__ ( self , dm ) : NEW_LINE INDENT self . dm = dm NEW_LINE DEDENT
def determine_upsample ( self , interpolation = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ upsampling ▁ rules . " NEW_LINE if interpolation is None : NEW_LINE INDENT interpolation = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_upsample ( interpolation . get ( name , col_info . upsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE if ( rule is not None ) and ( col_info . ndim > 0 ) : NEW_LINE INDENT raise NotImplementedError ( " Only ▁ scalar ▁ data ▁ can ▁ be ▁ upsampled . ▁ " " The ▁ { 0 } - dimensional ▁ source ▁ { 1 } ▁ was ▁ given ▁ the ▁ " " upsampling ▁ rule ▁ { 2 } . " . format ( col_info . ndim , name , rule ) ) NEW_LINE DEDENT rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT
def determine_downsample ( self , agg = None , use_cols = None ) : NEW_LINE INDENT " Resolve ▁ ( and ▁ if ▁ necessary ▁ validate ) ▁ sampling ▁ rules . " NEW_LINE if agg is None : NEW_LINE INDENT agg = dict ( ) NEW_LINE DEDENT if use_cols is None : NEW_LINE INDENT use_cols = self . dm . columns NEW_LINE DEDENT rules = dict ( ) NEW_LINE for name in use_cols : NEW_LINE INDENT col_info = self . dm . col_info [ name ] NEW_LINE rule = _validate_downsample ( agg . get ( name , col_info . downsample ) ) NEW_LINE rule = _normalize_string_none ( rule ) NEW_LINE rules [ name ] = rule NEW_LINE DEDENT return rules NEW_LINE DEDENT
def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ by _ edges STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be STRNEWLINE ▁ evaluated . ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' , ▁ ' ffill ' , ▁ ' bfill ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT
def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ Explain ▁ operation ▁ of ▁ DataMuxer . bin _ on . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ any ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever STRNEWLINE ▁ dimension ) ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by STRNEWLINE ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ table ▁ giving ▁ upsample ▁ and ▁ downsample ▁ rules ▁ for ▁ each ▁ data ▁ column STRNEWLINE ▁ and ▁ indicating ▁ whether ▁ those ▁ rules ▁ are ▁ applicable STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . dm . _bin_on ( source_name ) NEW_LINE bin_anchors , binning = self . dm . _bin_by_edges ( centers , bin_edges ) NEW_LINE # ▁ TODO ▁ Cache ▁ the ▁ grouping ▁ for ▁ reuse ▁ by ▁ resample . ENDCOM grouped = self . dm . _dataframe . groupby ( binning ) NEW_LINE counts = grouped . count ( ) NEW_LINE df = pd . DataFrame . from_dict ( _is_resampling_applicable ( counts ) ) NEW_LINE df [ ' upsample ' ] = self . determine_upsample ( interpolation , use_cols ) NEW_LINE df [ ' downsample ' ] = self . determine_downsample ( agg , use_cols ) NEW_LINE return df NEW_LINE DEDENT
def __init__ ( self ) : NEW_LINE INDENT self . sources = { } NEW_LINE self . col_info = { } NEW_LINE self . col_info [ ' time ' ] = ColSpec ( ' time ' , 0 , [ ] , ' linear ' , ' mean ' ) NEW_LINE self . _data = deque ( ) NEW_LINE self . _time = deque ( ) NEW_LINE self . _timestamps = deque ( ) NEW_LINE self . _timestamps_as_data = set ( ) NEW_LINE self . _known_events = set ( ) NEW_LINE self . _known_descriptors = set ( ) NEW_LINE self . _stale = True NEW_LINE self . plan = self . Planner ( self ) NEW_LINE self . convert_times = True NEW_LINE self . _reference_time = None NEW_LINE DEDENT
def reference_time ( self ) : NEW_LINE INDENT return self . _reference_time NEW_LINE DEDENT
def reference_time ( self , val ) : NEW_LINE INDENT self . _reference_time = pd . Timestamp ( val , unit = ' s ' ) NEW_LINE DEDENT
def columns ( self ) : NEW_LINE INDENT " The ▁ columns ▁ of ▁ DataFrames ▁ returned ▁ by ▁ methods ▁ that ▁ return ▁ DataFrames . " NEW_LINE return set ( self . sources ) | self . _time_columns NEW_LINE DEDENT
def _time_columns ( self ) : NEW_LINE INDENT ts_names = [ name + ' _ timestamp ' for name in self . _timestamps_as_data ] NEW_LINE return { ' time ' } | set ( ts_names ) NEW_LINE DEDENT
def append_events ( self , events , verbose = False ) : NEW_LINE INDENT """ Add ▁ a ▁ list ▁ of ▁ events ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ events ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ Events ▁ ( any ▁ objects ▁ with ▁ the ▁ expected ▁ attributes ▁ will ▁ do ) STRNEWLINE ▁ """ NEW_LINE for idx , event in enumerate ( events ) : NEW_LINE INDENT if verbose and idx % 25 == 0 : NEW_LINE INDENT print ( ' loading ▁ event ▁ % s ' % idx ) , NEW_LINE DEDENT self . append_event ( event ) NEW_LINE DEDENT DEDENT
def append_event ( self , event ) : NEW_LINE INDENT """ Add ▁ an ▁ event ▁ to ▁ the ▁ DataMuxer . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ event ▁ : ▁ Event STRNEWLINE ▁ Event ▁ Document ▁ or ▁ any ▁ object ▁ with ▁ the ▁ expected ▁ attributes STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ is _ new ▁ : ▁ bool STRNEWLINE ▁ True ▁ if ▁ event ▁ was ▁ added , ▁ False ▁ is ▁ it ▁ has ▁ already ▁ been ▁ added STRNEWLINE ▁ """ NEW_LINE if event . uid in self . _known_events : NEW_LINE INDENT return False NEW_LINE DEDENT self . _known_events . add ( event . uid ) NEW_LINE self . _stale = True NEW_LINE if event . descriptor . uid not in self . _known_descriptors : NEW_LINE INDENT self . _process_new_descriptor ( event . descriptor ) NEW_LINE # ▁ Both ▁ scalar ▁ and ▁ nonscalar ▁ data ▁ will ▁ get ▁ stored ▁ in ▁ the ▁ DataFrame . ENDCOM # ▁ This ▁ may ▁ be ▁ optimized ▁ later , ▁ but ▁ it ▁ might ▁ not ▁ actually ▁ help ▁ much . ENDCOM DEDENT self . _data . append ( { name : data for name , data in six . iteritems ( event . data ) } ) NEW_LINE self . _timestamps . append ( { name : ts for name , ts in six . iteritems ( event . timestamps ) } ) NEW_LINE self . _time . append ( event . time ) NEW_LINE return True NEW_LINE DEDENT
def _process_new_descriptor ( self , descriptor ) : NEW_LINE INDENT " Build ▁ a ▁ ColSpec ▁ and ▁ update ▁ state . " NEW_LINE for name , description in six . iteritems ( descriptor . data_keys ) : NEW_LINE # ▁ If ▁ we ▁ already ▁ have ▁ this ▁ source ▁ name , ▁ the ▁ unique ▁ source ENDCOM # ▁ identifiers ▁ must ▁ match . ▁ Ambiguous ▁ names ▁ are ▁ not ▁ allowed . ENDCOM INDENT if name in self . sources : NEW_LINE INDENT if self . sources [ name ] != description [ ' source ' ] : NEW_LINE INDENT raise ValueError ( " In ▁ a ▁ previously ▁ loaded ▁ descriptor , ▁ " " ' {0 } ' ▁ refers ▁ to ▁ { 1 } ▁ but ▁ in ▁ Event ▁ " " Descriptor ▁ { 2 } ▁ it ▁ refers ▁ to ▁ { 3 } . " . format ( name , self . sources [ name ] , descriptor . uid , description [ ' source ' ] ) ) NEW_LINE DEDENT if name == ' time ' : NEW_LINE # ▁ We ▁ can ▁ argue ▁ later ▁ about ▁ how ▁ best ▁ to ▁ handle ▁ this ▁ corner ENDCOM # ▁ case , ▁ but ▁ anything ▁ is ▁ better ▁ than ▁ silently ▁ mislabeling ENDCOM # ▁ data . ENDCOM INDENT raise ValueError ( " The ▁ name ▁ ' time ' ▁ is ▁ reserved ▁ and ▁ cannot ▁ " " be ▁ used ▁ as ▁ an ▁ alias . " ) NEW_LINE # ▁ If ▁ it ▁ is ▁ a ▁ new ▁ name , ▁ determine ▁ a ▁ ColSpec . ENDCOM DEDENT DEDENT else : NEW_LINE INDENT self . sources [ name ] = description [ ' source ' ] NEW_LINE if ' external ' in description and ' shape ' in description : NEW_LINE INDENT shape = description [ ' shape ' ] NEW_LINE ndim = len ( shape ) NEW_LINE DEDENT else : NEW_LINE # ▁ External ▁ data ▁ can ▁ be ▁ scalar . ▁ Nonscalar ▁ data ▁ must ENDCOM # ▁ have ▁ a ▁ specified ▁ shape . ▁ Thus , ▁ if ▁ no ▁ shape ▁ is ▁ given , ENDCOM # ▁ assume ▁ scalar . ENDCOM INDENT shape = None NEW_LINE ndim = 0 NEW_LINE DEDENT upsample = self . default_upsample NEW_LINE if ndim > 0 : NEW_LINE INDENT upsample = None NEW_LINE DEDENT col_info = ColSpec ( name , ndim , shape , upsample , self . default_downsample ) # ▁ defaults ENDCOM NEW_LINE # ▁ TODO ▁ Look ▁ up ▁ source - specific ▁ default ▁ in ▁ a ▁ config ▁ file ENDCOM # ▁ or ▁ some ▁ other ▁ source ▁ of ▁ reference ▁ data . ENDCOM self . col_info [ name ] = col_info NEW_LINE DEDENT DEDENT self . _known_descriptors . add ( descriptor . uid ) NEW_LINE DEDENT
def _dataframe ( self ) : NEW_LINE INDENT " See ▁ also ▁ to _ sparse _ dataframe , ▁ the ▁ public ▁ version ▁ of ▁ this . " NEW_LINE # ▁ Rebuild ▁ the ▁ DataFrame ▁ if ▁ more ▁ data ▁ has ▁ been ▁ added . ENDCOM if self . _stale : NEW_LINE INDENT df = pd . DataFrame ( list ( self . _data ) ) NEW_LINE df [ ' time ' ] = list ( self . _time ) NEW_LINE if self . _timestamps_as_data : NEW_LINE # ▁ Only ▁ build ▁ this ▁ if ▁ we ▁ need ▁ it . ENDCOM # ▁ TODO : ▁ We ▁ shouldn ' t ▁ have ▁ to ▁ build ENDCOM # ▁ the ▁ whole ▁ thing , ▁ but ▁ there ▁ is ▁ already ▁ a ▁ lot ▁ of ▁ trickiness ENDCOM # ▁ here ▁ so ▁ we ' ll ▁ worry ▁ about ▁ optimization ▁ later . ENDCOM INDENT timestamps = pd . DataFrame ( list ( self . _timestamps ) ) NEW_LINE DEDENT for source_name in self . _timestamps_as_data : NEW_LINE INDENT col_name = _timestamp_col_name ( source_name ) NEW_LINE df [ col_name ] = timestamps [ source_name ] NEW_LINE logger . debug ( " Including ▁ % s ▁ timestamps ▁ as ▁ data " , source_name ) NEW_LINE DEDENT self . _df = df . sort ( ' time ' ) . reset_index ( drop = True ) NEW_LINE self . _stale = False NEW_LINE DEDENT return self . _df NEW_LINE DEDENT
def to_sparse_dataframe ( self , include_all_timestamps = False ) : NEW_LINE INDENT """ Obtain ▁ all ▁ measurements ▁ in ▁ a ▁ DataFrame , ▁ one ▁ row ▁ per ▁ Event ▁ time . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ include _ all _ timestamps ▁ : ▁ bool STRNEWLINE ▁ The ▁ result ▁ will ▁ always ▁ contain ▁ a ▁ ' time ' ▁ column ▁ but , ▁ by ▁ default , STRNEWLINE ▁ not ▁ timestamps ▁ for ▁ individual ▁ data ▁ sources ▁ like ▁ ' motor _ timestamp ' . STRNEWLINE ▁ Set ▁ this ▁ to ▁ True ▁ to ▁ export ▁ timestamp ▁ columns ▁ for ▁ each ▁ data ▁ column STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ df ▁ : ▁ pandas . DataFrame STRNEWLINE ▁ """ NEW_LINE if include_all_timestamps : NEW_LINE INDENT raise NotImplementedError ( " TODO " ) NEW_LINE DEDENT result = self . _dataframe . copy ( ) NEW_LINE for col_name in self . _time_columns : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT return result NEW_LINE DEDENT
def _maybe_convert_times ( self , data ) : NEW_LINE INDENT if self . convert_times : NEW_LINE INDENT t = pd . to_datetime ( data , unit = ' s ' , utc = True ) . dt . tz_localize ( TZ ) NEW_LINE if self . reference_time is None : NEW_LINE INDENT return t NEW_LINE DEDENT else : NEW_LINE INDENT return t - self . reference_time NEW_LINE DEDENT DEDENT return data # ▁ no - op ENDCOM NEW_LINE DEDENT
def include_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Add ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ as ▁ a ▁ data ▁ column . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE # ▁ self . _ timestamps _ as _ data ▁ is ▁ a ▁ set ▁ of ▁ sources ▁ who ▁ timestamps ENDCOM # ▁ should ▁ be ▁ treated ▁ as ▁ data ▁ in ▁ the ▁ _ dataframe ▁ method ▁ above . ENDCOM self . _timestamps_as_data . add ( source_name ) NEW_LINE name = _timestamp_col_name ( source_name ) NEW_LINE self . col_info [ name ] = ColSpec ( name , 0 , None , None , np . mean ) NEW_LINE self . _stale = True NEW_LINE DEDENT
def remove_timestamp_data ( self , source_name ) : NEW_LINE INDENT """ Remove ▁ the ▁ exact ▁ timing ▁ of ▁ a ▁ data ▁ source ▁ from ▁ the ▁ data ▁ columns . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ one ▁ of ▁ the ▁ source ▁ names ▁ in ▁ DataMuxer . sources STRNEWLINE ▁ """ NEW_LINE self . _timestamps_as_data . remove ( source_name ) NEW_LINE # ▁ Do ▁ not ▁ force ▁ a ▁ rebuilt ▁ ( i . e . , ▁ self . _ stale ) . ▁ Just ▁ remove ▁ it ▁ here . ENDCOM del self . _df [ _timestamp_col_name ( source_name ) ] NEW_LINE DEDENT
def bin_on ( self , source_name , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ to ▁ align ▁ with ▁ the ▁ data ▁ from ▁ a ▁ particular ▁ source . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ source _ name ▁ : ▁ string STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE centers , bin_edges = self . _bin_on ( source_name ) NEW_LINE return self . bin_by_edges ( bin_edges , bin_anchors = centers , interpolation = interpolation , agg = agg , use_cols = use_cols ) NEW_LINE DEDENT
def _bin_on ( self , source_name ) : NEW_LINE INDENT " Compute ▁ bin ▁ edges ▁ spaced ▁ around ▁ centers ▁ defined ▁ by ▁ source _ name ▁ points . " NEW_LINE col = self . _dataframe [ source_name ] NEW_LINE centers = self . _dataframe [ ' time ' ] . reindex_like ( col . dropna ( ) ) . values NEW_LINE # ▁ [ 2 , ▁ 4 , ▁ 6 ] ▁ - > ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ENDCOM bin_edges = np . mean ( [ centers [ 1 : ] , centers [ : - 1 ] ] , 0 ) NEW_LINE # ▁ [ - inf , ▁ 3 , ▁ 5 , ▁ inf ] ▁ - > ▁ [ ( - inf , ▁ 3 ) , ▁ ( 3 , ▁ 5 ) , ▁ ( 5 , ▁ inf ) ] ENDCOM bin_edges = [ - np . inf ] + list ( np . repeat ( bin_edges , 2 ) ) + [ np . inf ] NEW_LINE bin_edges = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE return centers , bin_edges NEW_LINE DEDENT
def bin_by_edges ( self , bin_edges , bin_anchors , interpolation = None , agg = None , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ edges ▁ : ▁ list STRNEWLINE ▁ list ▁ of ▁ two - element ▁ items ▁ like ▁ [ ( t1 , ▁ t2 ) , ▁ ( t3 , ▁ t4 ) , ▁ . . . ] STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE bin_anchors , binning = self . _bin_by_edges ( bin_anchors , bin_edges ) NEW_LINE return self . resample ( bin_anchors , binning , interpolation , agg , use_cols = use_cols ) NEW_LINE DEDENT
def _bin_by_edges ( self , bin_anchors , bin_edges ) : NEW_LINE INDENT " Compute ▁ bin ▁ assignment ▁ and , ▁ if ▁ needed , ▁ bin _ anchors . " NEW_LINE time = self . _dataframe [ ' time ' ] . values NEW_LINE # ▁ Get ▁ edges ▁ into ▁ 1D ▁ array [ L , ▁ R , ▁ L , ▁ R , ▁ . . . ] ENDCOM edges_as_pairs = np . reshape ( bin_edges , ( - 1 , 2 ) ) NEW_LINE all_edges = np . ravel ( edges_as_pairs ) NEW_LINE if not np . all ( np . diff ( all_edges ) >= 0 ) : NEW_LINE INDENT raise ValueError ( " Illegal ▁ binning : ▁ the ▁ left ▁ edge ▁ must ▁ be ▁ less ▁ " " than ▁ the ▁ right ▁ edge . " ) NEW_LINE # ▁ Sort ▁ out ▁ where ▁ the ▁ array ▁ each ▁ time ▁ would ▁ be ▁ inserted . ENDCOM DEDENT binning = np . searchsorted ( all_edges , time ) . astype ( float ) NEW_LINE # ▁ Times ▁ that ▁ would ▁ get ▁ inserted ▁ at ▁ even ▁ positions ▁ are ▁ between ▁ bins . ENDCOM # ▁ Mark ▁ them ENDCOM binning [ binning % 2 == 0 ] = np . nan NEW_LINE binning //= 2 # ▁ Make ▁ bin ▁ number ▁ sequential , ▁ not ▁ odds ▁ only . ENDCOM NEW_LINE if bin_anchors is None : NEW_LINE INDENT bin_anchors = np . mean ( edges_as_pairs , axis = 1 ) # ▁ bin ▁ centers ENDCOM NEW_LINE DEDENT else : NEW_LINE INDENT if len ( bin_anchors ) != len ( bin_edges ) : NEW_LINE INDENT raise ValueError ( " There ▁ are ▁ { 0 } ▁ bin _ anchors ▁ but ▁ { 1 } ▁ pairs ▁ of ▁ " " bin _ edges . ▁ These ▁ must ▁ match . " . format ( len ( bin_anchors ) , len ( bin_edges ) ) ) NEW_LINE DEDENT DEDENT return bin_anchors , binning NEW_LINE DEDENT
def resample ( self , bin_anchors , binning , interpolation = None , agg = None , verify_integrity = True , use_cols = None ) : NEW_LINE INDENT """ STRNEWLINE ▁ Return ▁ data ▁ resampled ▁ into ▁ bins ▁ with ▁ the ▁ specified ▁ edges . STRNEWLINE STRNEWLINE ▁ Parameters STRNEWLINE ▁ - - - - - STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ These ▁ are ▁ time ▁ points ▁ where ▁ interpolated ▁ values ▁ will ▁ be ▁ evaluated . STRNEWLINE ▁ Bin ▁ centers ▁ are ▁ usually ▁ a ▁ good ▁ choice . STRNEWLINE ▁ bin _ anchors ▁ : ▁ list STRNEWLINE ▁ Bin ▁ assignment . ▁ Example : ▁ [ 1 , ▁ 1 , ▁ 2 , ▁ 2 , ▁ 3 , ▁ 3 ] ▁ puts ▁ six ▁ data ▁ points STRNEWLINE ▁ into ▁ three ▁ bins ▁ with ▁ two ▁ points ▁ each . STRNEWLINE ▁ interpolation ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ interpolation ▁ ( upsampling ) ▁ behavior ▁ of ▁ any STRNEWLINE ▁ data ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto STRNEWLINE ▁ one ▁ of ▁ the ▁ following ▁ interpolation ▁ methods . STRNEWLINE STRNEWLINE ▁ { None , ▁ ' linear ' , ▁ ' nearest ' , ▁ ' zero ' , ▁ ' slinear ' , ▁ ' quadratic ' , STRNEWLINE ▁ ' cubic ' } STRNEWLINE STRNEWLINE ▁ None ▁ means ▁ that ▁ each ▁ time ▁ bin ▁ must ▁ have ▁ at ▁ least ▁ one ▁ value . STRNEWLINE ▁ See ▁ scipy . interpolator ▁ for ▁ more ▁ on ▁ the ▁ other ▁ methods . STRNEWLINE ▁ agg ▁ : ▁ dict , ▁ optional STRNEWLINE ▁ Override ▁ the ▁ default ▁ reduction ▁ ( downsampling ) ▁ behavior ▁ of ▁ any ▁ data STRNEWLINE ▁ source ▁ by ▁ passing ▁ a ▁ dictionary ▁ of ▁ source ▁ names ▁ mapped ▁ onto ▁ any STRNEWLINE ▁ callable ▁ that ▁ reduces ▁ multiple ▁ data ▁ points ▁ ( of ▁ whatever ▁ dimension ) STRNEWLINE ▁ to ▁ a ▁ single ▁ data ▁ point . STRNEWLINE ▁ verify _ integrity ▁ : ▁ bool , ▁ optional STRNEWLINE ▁ For ▁ a ▁ cost ▁ in ▁ performance , ▁ verify ▁ that ▁ the ▁ downsampling ▁ function STRNEWLINE ▁ produces ▁ data ▁ of ▁ the ▁ expected ▁ shape . ▁ True ▁ by ▁ default . STRNEWLINE ▁ use _ cols ▁ : ▁ list , ▁ optional STRNEWLINE ▁ List ▁ of ▁ columns ▁ to ▁ include ▁ in ▁ binning ; ▁ use ▁ all ▁ columns ▁ by ▁ default . STRNEWLINE STRNEWLINE ▁ Returns STRNEWLINE ▁ - - - - - STRNEWLINE ▁ resampled _ df ▁ : ▁ pandas . DataFrame STRNEWLINE STRNEWLINE ▁ References STRNEWLINE ▁ - - - - - STRNEWLINE ▁ http : / / docs . scipy . org / doc / scipy / reference / generated / scipy . interpolate . interp1d . html STRNEWLINE ▁ """ NEW_LINE if use_cols is None : NEW_LINE INDENT use_cols = self . columns NEW_LINE DEDENT plan = self . Planner ( self ) NEW_LINE upsampling_rules = plan . determine_upsample ( interpolation , use_cols ) NEW_LINE downsampling_rules = plan . determine_downsample ( agg , use_cols ) NEW_LINE grouped = self . _dataframe . groupby ( binning ) NEW_LINE first_point = grouped . first ( ) NEW_LINE counts = grouped . count ( ) NEW_LINE resampling_requirements = _is_resampling_applicable ( counts ) NEW_LINE index = np . arange ( len ( bin_anchors ) ) NEW_LINE result = { } # ▁ dict ▁ of ▁ DataFrames , ▁ to ▁ become ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE for name in use_cols : NEW_LINE INDENT upsample = upsampling_rules [ name ] NEW_LINE downsample = downsampling_rules [ name ] NEW_LINE upsampling_possible = resampling_requirements [ ' upsampling _ possible ' ] [ name ] NEW_LINE downsampling_needed = resampling_requirements [ ' downsampling _ needed ' ] [ name ] NEW_LINE result [ name ] = pd . DataFrame ( index = index ) NEW_LINE # ▁ Put ▁ the ▁ first ▁ ( maybe ▁ only ) ▁ value ▁ into ▁ a ▁ Series . ENDCOM # ▁ We ▁ will ▁ overwrite ▁ as ▁ needed ▁ below . ENDCOM result [ name ] [ ' val ' ] = pd . Series ( data = first_point [ name ] ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM if not ( upsampling_possible or downsampling_needed ) : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ exactly ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE DEDENT result [ name ] [ ' count ' ] = counts [ name ] NEW_LINE # ▁ If ▁ any ▁ bin ▁ has ▁ no ▁ data , ▁ use ▁ the ▁ upsampling ▁ rule ▁ to ▁ interpolate ENDCOM # ▁ at ▁ the ▁ center ▁ of ▁ the ▁ empty ▁ bins . ▁ If ▁ there ▁ is ▁ no ▁ rule , ▁ simply ENDCOM # ▁ leave ▁ some ▁ bins ▁ empty . ▁ Do ▁ not ▁ raise ▁ an ▁ error . ENDCOM if upsampling_possible and ( upsample is not None ) : NEW_LINE INDENT if upsample in ( ' ffill ' , ' bfill ' ) : NEW_LINE INDENT result [ name ] [ ' val ' ] . fillna ( method = upsample , inplace = True ) NEW_LINE DEDENT else : NEW_LINE INDENT dense_col = self . _dataframe [ name ] . dropna ( ) NEW_LINE y = dense_col . values NEW_LINE x = self . _dataframe [ ' time ' ] . reindex_like ( dense_col ) . values NEW_LINE interpolator = interp1d ( x , y , kind = upsample ) NEW_LINE # ▁ Outside ▁ the ▁ limits ▁ of ▁ the ▁ data , ▁ the ▁ interpolator ▁ will ENDCOM # ▁ fail . ▁ Leave ▁ any ▁ such ▁ entires ▁ empty . ENDCOM is_safe = ( ( bin_anchors > np . min ( x ) ) & ( bin_anchors < np . max ( x ) ) ) NEW_LINE safe_times = bin_anchors [ is_safe ] NEW_LINE safe_bins = index [ is_safe ] NEW_LINE interp_points = pd . Series ( interpolator ( safe_times ) , index = safe_bins ) NEW_LINE logger . debug ( " Interpolating ▁ to ▁ fill ▁ % d ▁ of ▁ % d ▁ " " empty ▁ bins ▁ in ▁ % s " , len ( safe_bins ) , ( counts [ name ] == 0 ) . sum ( ) , name ) NEW_LINE result [ name ] [ ' val ' ] . fillna ( interp_points , inplace = True ) NEW_LINE # ▁ Short - circuit ▁ if ▁ we ▁ are ▁ done . ENDCOM DEDENT DEDENT if not downsampling_needed : NEW_LINE INDENT logger . debug ( " % s ▁ has ▁ at ▁ most ▁ one ▁ data ▁ point ▁ per ▁ bin " , name ) NEW_LINE continue NEW_LINE # ▁ Multi - valued ▁ bins ▁ must ▁ be ▁ downsampled ▁ ( reduced ) . ▁ If ▁ there ▁ is ▁ no ENDCOM # ▁ rule ▁ for ▁ downsampling , ▁ we ▁ have ▁ no ▁ recourse : ▁ we ▁ must ▁ raise . ENDCOM DEDENT if ( downsample is None ) : NEW_LINE INDENT raise BinningError ( " The ▁ specified ▁ binning ▁ puts ▁ multiple ▁ " " ' {0 } ' ▁ measurements ▁ in ▁ at ▁ least ▁ one ▁ bin , ▁ " " and ▁ there ▁ is ▁ no ▁ rule ▁ for ▁ downsampling ▁ " " ( i . e . , ▁ reducing ) ▁ it . " . format ( name ) ) NEW_LINE DEDENT if verify_integrity and callable ( downsample ) : NEW_LINE INDENT downsample = _build_verified_downsample ( downsample , self . col_info [ name ] . shape ) NEW_LINE DEDENT g = grouped [ name ] # ▁ for ▁ brevity ENDCOM NEW_LINE if self . col_info [ name ] . ndim == 0 : NEW_LINE INDENT logger . debug ( " The ▁ scalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE # ▁ For ▁ scalars , ▁ pandas ▁ knows ▁ what ▁ to ▁ do . ENDCOM downsampled = g . agg ( downsample ) NEW_LINE std_series = g . std ( ) NEW_LINE max_series = g . max ( ) NEW_LINE min_series = g . min ( ) NEW_LINE DEDENT else : NEW_LINE # ▁ For ▁ nonscalars , ▁ we ▁ are ▁ abusing ▁ groupby ▁ and ▁ must ▁ go ▁ to ▁ a ENDCOM # ▁ a ▁ little ▁ more ▁ trouble ▁ to ▁ guarantee ▁ success . ENDCOM INDENT logger . debug ( " The ▁ nonscalar ▁ column ▁ % s ▁ must ▁ be ▁ downsampled . " , name ) NEW_LINE if not callable ( downsample ) : NEW_LINE # ▁ Do ▁ this ▁ lookup ▁ here ▁ so ▁ that ▁ strings ▁ can ▁ be ▁ passed ENDCOM # ▁ in ▁ the ▁ call ▁ to ▁ resample . ENDCOM INDENT downsample = ColSpec . _downsample_mapping [ downsample ] NEW_LINE DEDENT downsampled = g . apply ( lambda x : downsample ( np . asarray ( x . dropna ( ) ) ) ) NEW_LINE std_series = g . apply ( lambda x : np . std ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE max_series = g . apply ( lambda x : np . max ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE min_series = g . apply ( lambda x : np . min ( np . asarray ( x . dropna ( ) ) , 0 ) ) NEW_LINE # ▁ This ▁ ( counts [ name ] ▁ > ▁ 1 ) ▁ is ▁ redundant , ▁ but ▁ there ▁ is ▁ no ▁ clean ▁ way ▁ to ENDCOM # ▁ pass ▁ it ▁ here ▁ without ▁ refactoring . ▁ Not ▁ a ▁ huge ▁ cost . ENDCOM DEDENT result [ name ] [ ' val ' ] . where ( ~ ( counts [ name ] > 1 ) , downsampled , inplace = True ) NEW_LINE result [ name ] [ ' std ' ] = std_series NEW_LINE result [ name ] [ ' max ' ] = max_series NEW_LINE result [ name ] [ ' min ' ] = min_series NEW_LINE DEDENT result = pd . concat ( result , axis = 1 ) # ▁ one ▁ MultiIndexed ▁ DataFrame ENDCOM NEW_LINE result . index . name = ' bin ' NEW_LINE # ▁ Convert ▁ time ▁ timestamp ▁ or ▁ timedelta , ▁ depending ▁ on ▁ the ▁ state ▁ of ENDCOM # ▁ self . convert _ times ▁ and ▁ self . reference _ time . ENDCOM for col_name in self . _time_columns : NEW_LINE INDENT if isinstance ( result [ col_name ] , pd . DataFrame ) : NEW_LINE INDENT subcols = result [ col_name ] . columns NEW_LINE for subcol in subcols & { ' max ' , ' min ' , ' val ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = self . _maybe_convert_times ( result [ ( col_name , subcol ) ] ) NEW_LINE DEDENT for subcol in subcols & { ' std ' } : NEW_LINE INDENT result [ ( col_name , subcol ) ] = pd . to_timedelta ( result [ ( col_name , subcol ) ] , unit = ' s ' ) NEW_LINE DEDENT DEDENT else : NEW_LINE INDENT result [ col_name ] = self . _maybe_convert_times ( result [ col_name ] ) NEW_LINE DEDENT DEDENT return result NEW_LINE DEDENT
def __getitem__ ( self , source_name ) : NEW_LINE INDENT if source_name not in list ( self . col_info . keys ( ) ) + [ ' time ' ] : NEW_LINE INDENT raise KeyError ( " No ▁ data ▁ from ▁ a ▁ source ▁ called ▁ ' {0 } ' ▁ has ▁ been ▁ " " added . " . format ( source_name ) ) NEW_LINE # ▁ Unlike ▁ output ▁ from ▁ binning ▁ functions , ▁ this ▁ is ▁ indexed ENDCOM # ▁ on ▁ time . ENDCOM DEDENT result = self . _dataframe [ source_name ] . dropna ( ) NEW_LINE result . index = self . _dataframe [ ' time ' ] . reindex_like ( result ) NEW_LINE return result NEW_LINE DEDENT
def __getattr__ ( self , attr ) : NEW_LINE # ▁ Developer ▁ beware : ▁ if ▁ any ▁ properties ▁ raise ▁ an ▁ AttributeError , ENDCOM # ▁ this ▁ will ▁ mask ▁ it . ▁ Comment ▁ this ▁ magic ▁ method ▁ to ▁ debug ▁ properties . ENDCOM INDENT if attr in self . col_info . keys ( ) : NEW_LINE INDENT return self [ attr ] NEW_LINE DEDENT else : NEW_LINE INDENT raise AttributeError ( " DataMuxer ▁ has ▁ no ▁ attribute ▁ { 0 } ▁ and ▁ no ▁ " " data ▁ source ▁ named ▁ ' {0 } ' " . format ( attr ) ) NEW_LINE DEDENT DEDENT
def ncols ( self ) : NEW_LINE INDENT """ STRNEWLINE ▁ The ▁ number ▁ of ▁ columns ▁ that ▁ the ▁ DataMuxer ▁ contains STRNEWLINE ▁ """ NEW_LINE return len ( self . col_info ) NEW_LINE DEDENT
def col_info_by_ndim ( self ) : NEW_LINE INDENT """ Dictionary ▁ mapping ▁ dimensionality ▁ ( ndim ) ▁ onto ▁ a ▁ list ▁ of ▁ ColSpecs """ NEW_LINE result = { } NEW_LINE for name , col_spec in six . iteritems ( self . col_info ) : NEW_LINE INDENT try : NEW_LINE INDENT result [ col_spec . ndim ] NEW_LINE DEDENT except KeyError : NEW_LINE INDENT result [ col_spec . ndim ] = [ ] NEW_LINE DEDENT result [ col_spec . ndim ] . append ( col_spec ) NEW_LINE DEDENT return result NEW_LINE DEDENT
def __str__ ( self ) : NEW_LINE INDENT return " project ▁ { 0 } ▁ - ▁ { 1 } " . format ( self . project_id , self . slug ) NEW_LINE DEDENT
def save ( self , * args , ** kwargs ) : NEW_LINE INDENT if not self . _importing or not self . modified_date : NEW_LINE INDENT self . modified_date = timezone . now ( ) NEW_LINE DEDENT return super ( ) . save ( * args , ** kwargs ) NEW_LINE DEDENT
def __str__ ( self ) : NEW_LINE INDENT return self . title NEW_LINE DEDENT
def prepare ( self ) : NEW_LINE INDENT """ Initializes ▁ the ▁ screen ▁ to ▁ abcdefghij ▁ on ▁ the ▁ first ▁ line ▁ with ▁ the ▁ cursor STRNEWLINE ▁ on ▁ the ▁ ' e ' . """ NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE escio . Write ( " abcdefghij " ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE DEDENT
def test_EL_Default ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT
def test_EL_0 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ right ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 0 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ " abcd " + 6 * NUL ] ) NEW_LINE DEDENT
def test_EL_1 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ to ▁ left ▁ of ▁ cursor . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 1 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 5 * blank ( ) + " fghij " ] ) NEW_LINE DEDENT
def test_EL_2 ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ whole ▁ line . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT
def test_EL_IgnoresScrollRegion ( self ) : NEW_LINE INDENT """ Should ▁ erase ▁ whole ▁ line . """ NEW_LINE self . prepare ( ) NEW_LINE esccmd . DECSET ( esccmd . DECLRMM ) NEW_LINE esccmd . DECSLRM ( 2 , 4 ) NEW_LINE esccmd . CUP ( Point ( 5 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE esccmd . DECRESET ( esccmd . DECLRMM ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 10 , 1 ) , [ 10 * NUL ] ) NEW_LINE DEDENT
def test_EL_doesNotRespectDECProtection ( self ) : NEW_LINE INDENT """ EL ▁ respects ▁ DECSCA . """ NEW_LINE escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . DECSCA ( 1 ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . DECSCA ( 0 ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ NUL * 3 ] ) NEW_LINE DEDENT
def test_EL_respectsISOProtection ( self ) : NEW_LINE INDENT """ EL ▁ respects ▁ SPA / EPA . """ NEW_LINE escio . Write ( " a " ) NEW_LINE escio . Write ( " b " ) NEW_LINE esccmd . SPA ( ) NEW_LINE escio . Write ( " c " ) NEW_LINE esccmd . EPA ( ) NEW_LINE esccmd . CUP ( Point ( 1 , 1 ) ) NEW_LINE esccmd . EL ( 2 ) NEW_LINE AssertScreenCharsInRectEqual ( Rect ( 1 , 1 , 3 , 1 ) , [ blank ( ) * 2 + " c " ] ) NEW_LINE DEDENT
def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 3 , 3 , 3 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 3 , 3 , 3 ] ) NEW_LINE DEDENT
def test_preserve_shape ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE arg = 2 NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE arg = [ 1.5 , 2 , 2.5 ] NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg ) ) ) NEW_LINE assert_equal ( shape ( arg ) , shape ( lut ( arg , nu = 1 ) ) ) NEW_LINE DEDENT
def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 2 , 3 ] NEW_LINE y = [ 0 , 2 , 4 ] NEW_LINE lut = UnivariateSpline ( x , y , k = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , [ 1 , 3 ] ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] ) , [ 0 , 1 , 2 ] ) NEW_LINE DEDENT
def test_subclassing ( self ) : NEW_LINE # ▁ See ▁ # 731 ENDCOM INDENT class ZeroSpline ( UnivariateSpline ) : NEW_LINE INDENT def __call__ ( self , x ) : NEW_LINE INDENT return 0 * array ( x ) NEW_LINE DEDENT DEDENT sp = ZeroSpline ( [ 1 , 2 , 3 , 4 , 5 ] , [ 3 , 2 , 3 , 2 , 3 ] , k = 2 ) NEW_LINE assert_array_equal ( sp ( [ 1.5 , 2.5 ] ) , [ 0. , 0. ] ) NEW_LINE DEDENT
def test_empty_input ( self ) : NEW_LINE # ▁ Test ▁ whether ▁ empty ▁ input ▁ returns ▁ an ▁ empty ▁ output . ▁ Ticket ▁ 1014 ENDCOM INDENT x = [ 1 , 3 , 5 , 7 , 9 ] NEW_LINE y = [ 0 , 4 , 9 , 12 , 21 ] NEW_LINE spl = UnivariateSpline ( x , y , k = 3 ) NEW_LINE assert_array_equal ( spl ( [ ] ) , array ( [ ] ) ) NEW_LINE DEDENT
def test_resize_regression ( self ) : NEW_LINE INDENT """ Regression ▁ test ▁ for ▁ # 1375 . """ NEW_LINE x = [ - 1. , - 0.65016502 , - 0.58856235 , - 0.26903553 , - 0.17370892 , - 0.10011001 , 0. , 0.10011001 , 0.17370892 , 0.26903553 , 0.58856235 , 0.65016502 , 1. ] NEW_LINE y = [ 1. , 0.62928599 , 0.5797223 , 0.39965815 , 0.36322694 , 0.3508061 , 0.35214793 , 0.3508061 , 0.36322694 , 0.39965815 , 0.5797223 , 0.62928599 , 1. ] NEW_LINE w = [ 1.00000000e+12 , 6.88875973e+02 , 4.89314737e+02 , 4.26864807e+02 , 6.07746770e+02 , 4.51341444e+02 , 3.17480210e+02 , 4.51341444e+02 , 6.07746770e+02 , 4.26864807e+02 , 4.89314737e+02 , 6.88875973e+02 , 1.00000000e+12 ] NEW_LINE spl = UnivariateSpline ( x = x , y = y , w = w , s = None ) NEW_LINE desired = array ( [ 0.35100374 , 0.51715855 , 0.87789547 , 0.98719344 ] ) NEW_LINE assert_allclose ( spl ( [ 0.1 , 0.5 , 0.9 , 0.99 ] ) , desired , atol = 5e-4 ) NEW_LINE DEDENT
def test_out_of_range_regression ( self ) : NEW_LINE # ▁ Test ▁ different ▁ extrapolation ▁ modes . ▁ See ▁ ticket ▁ 3557 ENDCOM INDENT x = np . arange ( 5 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE xp = linspace ( - 8 , 13 , 100 ) NEW_LINE xp_zeros = xp . copy ( ) NEW_LINE xp_zeros [ np . logical_or ( xp_zeros < 0. , xp_zeros > 4. ) ] = 0 NEW_LINE xp_clip = xp . copy ( ) NEW_LINE xp_clip [ xp_clip < x [ 0 ] ] = x [ 0 ] NEW_LINE xp_clip [ xp_clip > x [ - 1 ] ] = x [ - 1 ] NEW_LINE for cls in [ UnivariateSpline , InterpolatedUnivariateSpline ] : NEW_LINE INDENT spl = cls ( x = x , y = y ) NEW_LINE for ext in [ 0 , ' extrapolate ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 1 , ' zeros ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE DEDENT for ext in [ 2 , ' raise ' ] : NEW_LINE INDENT assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE DEDENT for ext in [ 3 , ' const ' ] : NEW_LINE INDENT assert_allclose ( spl ( xp , ext = ext ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( cls ( x , y , ext = ext ) ( xp ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE # ▁ also ▁ test ▁ LSQUnivariateSpline ▁ [ which ▁ needs ▁ explicit ▁ knots ] ENDCOM DEDENT DEDENT t = spl . get_knots ( ) [ 3 : 4 ] # ▁ interior ▁ knots ▁ w / ▁ default ▁ k = 3 ENDCOM NEW_LINE spl = LSQUnivariateSpline ( x , y , t ) NEW_LINE assert_allclose ( spl ( xp , ext = 0 ) , xp ** 3 , atol = 1e-16 ) NEW_LINE assert_allclose ( spl ( xp , ext = 1 ) , xp_zeros ** 3 , atol = 1e-16 ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = 2 ) ) NEW_LINE assert_allclose ( spl ( xp , ext = 3 ) , xp_clip ** 3 , atol = 1e-16 ) NEW_LINE # ▁ also ▁ make ▁ sure ▁ that ▁ unknown ▁ values ▁ for ▁ ` ext ` ▁ are ▁ caught ▁ early ENDCOM for ext in [ - 1 , ' unknown ' ] : NEW_LINE INDENT spl = UnivariateSpline ( x , y ) NEW_LINE assert_raises ( ValueError , spl , xp , ** dict ( ext = ext ) ) NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , ext = ext ) ) NEW_LINE DEDENT DEDENT
def test_lsq_fpchec ( self ) : NEW_LINE INDENT xs = np . arange ( 100 ) * 1. NEW_LINE ys = np . arange ( 100 ) * 1. NEW_LINE knots = np . linspace ( 0 , 99 , 10 ) NEW_LINE bbox = ( - 1 , 101 ) NEW_LINE assert_raises ( ValueError , LSQUnivariateSpline , xs , ys , knots , bbox = bbox ) NEW_LINE DEDENT
def test_derivative_and_antiderivative ( self ) : NEW_LINE # ▁ Thin ▁ wrappers ▁ to ▁ splder / splantider , ▁ so ▁ light ▁ smoke ▁ test ▁ only . ENDCOM INDENT x = np . linspace ( 0 , 1 , 70 ) ** 3 NEW_LINE y = np . cos ( x ) NEW_LINE spl = UnivariateSpline ( x , y , s = 0 ) NEW_LINE spl2 = spl . antiderivative ( 2 ) . derivative ( 2 ) NEW_LINE assert_allclose ( spl ( 0.3 ) , spl2 ( 0.3 ) ) NEW_LINE spl2 = spl . antiderivative ( 1 ) NEW_LINE assert_allclose ( spl2 ( 0.6 ) - spl2 ( 0.2 ) , spl . integral ( 0.2 , 0.6 ) ) NEW_LINE DEDENT
def test_nan ( self ) : NEW_LINE # ▁ bail ▁ out ▁ early ▁ if ▁ the ▁ input ▁ data ▁ contains ▁ nans ENDCOM INDENT x = np . arange ( 10 , dtype = float ) NEW_LINE y = x ** 3 NEW_LINE for z in [ np . nan , np . inf , - np . inf ] : NEW_LINE INDENT y [ - 1 ] = z NEW_LINE assert_raises ( ValueError , UnivariateSpline , ** dict ( x = x , y = y , check_finite = True ) ) NEW_LINE DEDENT DEDENT
def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_almost_equal ( lut ( 2 , 2 ) , 3. ) NEW_LINE DEDENT
def test_bilinearity ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE # ▁ This ▁ seems ▁ to ▁ fail ▁ ( ier = 1 , ▁ see ▁ ticket ▁ 1642 ) . ENDCOM INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE for xa , xb in zip ( tx [ : - 1 ] , tx [ 1 : ] ) : NEW_LINE INDENT for ya , yb in zip ( ty [ : - 1 ] , ty [ 1 : ] ) : NEW_LINE INDENT for t in [ 0.1 , 0.5 , 0.9 ] : NEW_LINE INDENT for s in [ 0.3 , 0.4 , 0.7 ] : NEW_LINE INDENT xp = xa * ( 1 - t ) + xb * t NEW_LINE yp = ya * ( 1 - s ) + yb * s NEW_LINE zp = ( + lut ( xa , ya ) * ( 1 - t ) * ( 1 - s ) + lut ( xb , ya ) * t * ( 1 - s ) + lut ( xa , yb ) * ( 1 - t ) * s + lut ( xb , yb ) * t * s ) NEW_LINE assert_almost_equal ( lut ( xp , yp ) , zp ) NEW_LINE DEDENT DEDENT DEDENT DEDENT DEDENT
def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 8 , 8 , 8 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT tx , ty = lut . get_knots ( ) NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE DEDENT
def test_empty_input ( self ) : NEW_LINE # ▁ Test ▁ whether ▁ empty ▁ inputs ▁ returns ▁ an ▁ empty ▁ output . ▁ Ticket ▁ 1014 ENDCOM INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE s = 0.1 NEW_LINE tx = [ 1 + s , 3 - s ] NEW_LINE ty = [ 1 + s , 3 - s ] NEW_LINE with warnings . catch_warnings ( record = True ) : # ▁ coefficients ▁ of ▁ the ▁ . . . ENDCOM NEW_LINE INDENT lut = LSQBivariateSpline ( x , y , z , tx , ty , kx = 1 , ky = 1 ) NEW_LINE DEDENT assert_array_equal ( lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_equal ( lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT
def test_linear_constant ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 3 , 3 , 3 , 3 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT
def test_linear_1d ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 3 , 3 , 3 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = [ 0 , 0 , 0 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 ) NEW_LINE assert_array_almost_equal ( lut . get_knots ( ) , ( [ 1 , 1 , 3 , 3 ] , [ 1 , 1 , 3 , 3 ] ) ) NEW_LINE assert_array_almost_equal ( lut . get_coeffs ( ) , [ 0 , 0 , 4 , 4 ] ) NEW_LINE assert_almost_equal ( lut . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 0 , 0 ] , [ 1 , 1 ] , [ 2 , 2 ] ] ) NEW_LINE DEDENT
def test_integral ( self ) : NEW_LINE INDENT x = [ 1 , 1 , 1 , 2 , 2 , 2 , 4 , 4 , 4 ] NEW_LINE y = [ 1 , 2 , 3 , 1 , 2 , 3 , 1 , 2 , 3 ] NEW_LINE z = array ( [ 0 , 7 , 8 , 3 , 4 , 7 , 1 , 3 , 4 ] ) NEW_LINE with warnings . catch_warnings ( ) : NEW_LINE # ▁ This ▁ seems ▁ to ▁ fail ▁ ( ier = 1 , ▁ see ▁ ticket ▁ 1642 ) . ENDCOM INDENT warnings . simplefilter ( ' ignore ' , UserWarning ) NEW_LINE lut = SmoothBivariateSpline ( x , y , z , kx = 1 , ky = 1 , s = 0 ) NEW_LINE DEDENT tx = [ 1 , 2 , 4 ] NEW_LINE ty = [ 1 , 2 , 3 ] NEW_LINE tz = lut ( tx , ty ) NEW_LINE trpz = .25 * ( diff ( tx ) [ : , None ] * diff ( ty ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz ) NEW_LINE lut2 = SmoothBivariateSpline ( x , y , z , kx = 2 , ky = 2 , s = 0 ) NEW_LINE assert_almost_equal ( lut2 . integral ( tx [ 0 ] , tx [ - 1 ] , ty [ 0 ] , ty [ - 1 ] ) , trpz , decimal = 0 ) # ▁ the ▁ quadratures ▁ give ▁ 23.75 ▁ and ▁ 23.85 ENDCOM NEW_LINE tz = lut ( tx [ : - 1 ] , ty [ : - 1 ] ) NEW_LINE trpz = .25 * ( diff ( tx [ : - 1 ] ) [ : , None ] * diff ( ty [ : - 1 ] ) [ None , : ] * ( tz [ : - 1 , : - 1 ] + tz [ 1 : , : - 1 ] + tz [ : - 1 , 1 : ] + tz [ 1 : , 1 : ] ) ) . sum ( ) NEW_LINE assert_almost_equal ( lut . integral ( tx [ 0 ] , tx [ - 2 ] , ty [ 0 ] , ty [ - 2 ] ) , trpz ) NEW_LINE DEDENT
def test_rerun_lwrk2_too_small ( self ) : NEW_LINE # ▁ in ▁ this ▁ setting , ▁ lwrk2 ▁ is ▁ too ▁ small ▁ in ▁ the ▁ default ▁ run . ▁ Here ▁ we ENDCOM # ▁ check ▁ for ▁ equality ▁ with ▁ the ▁ bisplrep / bisplev ▁ output ▁ because ▁ there , ENDCOM # ▁ an ▁ automatic ▁ re - run ▁ of ▁ the ▁ spline ▁ representation ▁ is ▁ done ▁ if ▁ ier > 10 . ENDCOM INDENT x = np . linspace ( - 2 , 2 , 80 ) NEW_LINE y = np . linspace ( - 2 , 2 , 80 ) NEW_LINE z = x + y NEW_LINE xi = np . linspace ( - 1 , 1 , 100 ) NEW_LINE yi = np . linspace ( - 2 , 2 , 100 ) NEW_LINE tck = bisplrep ( x , y , z ) NEW_LINE res1 = bisplev ( xi , yi , tck ) NEW_LINE interp_ = SmoothBivariateSpline ( x , y , z ) NEW_LINE res2 = interp_ ( xi , yi ) NEW_LINE assert_almost_equal ( res1 , res2 ) NEW_LINE DEDENT
def setUp ( self ) : NEW_LINE # ▁ define ▁ the ▁ input ▁ data ▁ and ▁ coordinates ENDCOM INDENT ntheta , nphi = 70 , 90 NEW_LINE theta = linspace ( 0.5 / ( ntheta - 1 ) , 1 - 0.5 / ( ntheta - 1 ) , ntheta ) * pi NEW_LINE phi = linspace ( 0.5 / ( nphi - 1 ) , 1 - 0.5 / ( nphi - 1 ) , nphi ) * 2. * pi NEW_LINE data = ones ( ( theta . shape [ 0 ] , phi . shape [ 0 ] ) ) NEW_LINE # ▁ define ▁ knots ▁ and ▁ extract ▁ data ▁ values ▁ at ▁ the ▁ knots ENDCOM knotst = theta [ : : 5 ] NEW_LINE knotsp = phi [ : : 5 ] NEW_LINE knotdata = data [ : : 5 , : : 5 ] NEW_LINE # ▁ calculate ▁ spline ▁ coefficients ENDCOM lats , lons = meshgrid ( theta , phi ) NEW_LINE lut_lsq = LSQSphereBivariateSpline ( lats . ravel ( ) , lons . ravel ( ) , data . T . ravel ( ) , knotst , knotsp ) NEW_LINE self . lut_lsq = lut_lsq NEW_LINE self . data = knotdata NEW_LINE self . new_lons , self . new_lats = knotsp , knotst NEW_LINE DEDENT
def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut_lsq . get_residual ( ) , 0.0 ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( self . new_lats , self . new_lons ) , self . data ) NEW_LINE DEDENT
def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut_lsq ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT
def setUp ( self ) : NEW_LINE INDENT theta = array ( [ .25 * pi , .25 * pi , .25 * pi , .5 * pi , .5 * pi , .5 * pi , .75 * pi , .75 * pi , .75 * pi ] ) NEW_LINE phi = array ( [ .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi , .5 * pi , pi , 1.5 * pi ] ) NEW_LINE r = array ( [ 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 , 3 ] ) NEW_LINE self . lut = SmoothSphereBivariateSpline ( theta , phi , r , s = 1E10 ) NEW_LINE DEDENT
def test_linear_constant ( self ) : NEW_LINE INDENT assert_almost_equal ( self . lut . get_residual ( ) , 0. ) NEW_LINE assert_array_almost_equal ( self . lut ( [ 1 , 1.5 , 2 ] , [ 1 , 1.5 ] ) , [ [ 3 , 3 ] , [ 3 , 3 ] , [ 3 , 3 ] ] ) NEW_LINE DEDENT
def test_empty_input ( self ) : NEW_LINE INDENT assert_array_almost_equal ( self . lut ( [ ] , [ ] ) , np . zeros ( ( 0 , 0 ) ) ) NEW_LINE assert_array_almost_equal ( self . lut ( [ ] , [ ] , grid = False ) , np . zeros ( ( 0 , ) ) ) NEW_LINE DEDENT
def test_defaults ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT
def test_evaluate ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE xi = [ 1 , 2.3 , 5.3 , 0.5 , 3.3 , 1.2 , 3 ] NEW_LINE yi = [ 1 , 3.3 , 1.2 , 4.0 , 5.0 , 1.0 , 3 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT
def test_derivatives_grid ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ [ 0 , 0 , - 20 , 0 , 0 ] , [ 0 , 0 , 13 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] , [ 0 , 0 , - 11 , 0 , 0 ] , [ 0 , 0 , 4 , 0 , 0 ] ] ) / 6. NEW_LINE dy = array ( [ [ 4 , - 1 , 0 , 1 , - 4 ] , [ 4 , - 1 , 0 , 1 , - 4 ] , [ 0 , 1.5 , 0 , - 1.5 , 0 ] , [ 2 , .25 , 0 , - .25 , - 2 ] , [ 4 , - 1 , 0 , 1 , - 4 ] ] ) NEW_LINE dxdy = array ( [ [ 40 , - 25 , 0 , 25 , - 40 ] , [ - 26 , 16.25 , 0 , - 16.25 , 26 ] , [ - 8 , 5 , 0 , - 5 , 8 ] , [ 22 , - 13.75 , 0 , 13.75 , - 22 ] , [ - 8 , 5 , 0 , - 5 , 8 ] ] ) / 6. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 ) , dxdy ) NEW_LINE DEDENT
def test_derivatives ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE dx = array ( [ 0 , 0 , 2. / 3 , 0 , 0 ] ) NEW_LINE dy = array ( [ 4 , - 1 , 0 , - .25 , - 4 ] ) NEW_LINE dxdy = array ( [ 160 , 65 , 0 , 55 , 32 ] ) / 24. NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , grid = False ) , dx ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dy = 1 , grid = False ) , dy ) NEW_LINE assert_array_almost_equal ( lut ( x , y , dx = 1 , dy = 1 , grid = False ) , dxdy ) NEW_LINE DEDENT
def test_broadcast ( self ) : NEW_LINE INDENT x = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE y = array ( [ 1 , 2 , 3 , 4 , 5 ] ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectBivariateSpline ( x , y , z ) NEW_LINE assert_allclose ( lut ( x , y ) , lut ( x [ : , None ] , y [ None , : ] , grid = False ) ) NEW_LINE DEDENT
def test_defaults ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE assert_array_almost_equal ( lut ( x , y ) , z ) NEW_LINE DEDENT
def test_evaluate ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE yi = [ 0.2 , 1 , 2.3 , 2.35 , 3.0 , 3.99 , 5.25 ] NEW_LINE xi = [ 1.5 , 0.4 , 1.1 , 0.45 , 0.2345 , 1. , 0.0001 ] NEW_LINE zi = lut . ev ( xi , yi ) NEW_LINE zi2 = array ( [ lut ( xp , yp ) [ 0 , 0 ] for xp , yp in zip ( xi , yi ) ] ) NEW_LINE assert_almost_equal ( zi , zi2 ) NEW_LINE DEDENT
def test_derivatives_grid ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 ) , _numdiff_2d ( lut , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 ) , _numdiff_2d ( lut , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT
def test_derivatives ( self ) : NEW_LINE INDENT y = linspace ( 0.01 , 2 * pi - 0.01 , 7 ) NEW_LINE x = linspace ( 0.01 , pi - 0.01 , 7 ) NEW_LINE z = array ( [ [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 3 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 2 , 2 , 1 , 2 , 1 ] , [ 1 , 2 , 1 , 2 , 1 , 2 , 1 ] ] ) NEW_LINE lut = RectSphereBivariateSpline ( x , y , z ) NEW_LINE y = linspace ( 0.02 , 2 * pi - 0.02 , 7 ) NEW_LINE x = linspace ( 0.02 , pi - 0.02 , 7 ) NEW_LINE assert_equal ( lut ( x , y , dtheta = 1 , grid = False ) . shape , x . shape ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dy = 1 ) , rtol = 1e-4 , atol = 1e-4 ) NEW_LINE assert_allclose ( lut ( x , y , dtheta = 1 , dphi = 1 , grid = False ) , _numdiff_2d ( lambda x , y : lut ( x , y , grid = False ) , x , y , dx = 1 , dy = 1 , eps = 1e-6 ) , rtol = 1e-3 , atol = 1e-3 ) NEW_LINE DEDENT
def __init__ ( self ) : Element . __init__ ( self ) NEW_LINE def get_coordinate ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0,0 ▁ coordinate . STRNEWLINE TABSYMBOL TABSYMBOL Coordinates ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 , ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return ( 0 , 0 ) NEW_LINE DEDENT
def get_rotation ( self ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Get ▁ the ▁ 0 ▁ degree ▁ rotation . STRNEWLINE TABSYMBOL TABSYMBOL Rotations ▁ are ▁ irrelevant ▁ in ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ return ▁ 0 STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE return 0 NEW_LINE DEDENT
def create_shapes ( self ) : NEW_LINE INDENT """ Precalculate ▁ relative ▁ coordinates . """ NEW_LINE Element . create_shapes ( self ) NEW_LINE self . _sink_rot = None NEW_LINE self . _source_rot = None NEW_LINE self . _sink_coor = None NEW_LINE self . _source_coor = None NEW_LINE # get ▁ the ▁ source ▁ coordinate ENDCOM connector_length = self . get_source ( ) . get_connector_length ( ) NEW_LINE self . x1 , self . y1 = Utils . get_rotated_coordinate ( ( connector_length , 0 ) , self . get_source ( ) . get_rotation ( ) ) NEW_LINE # get ▁ the ▁ sink ▁ coordinate ENDCOM connector_length = self . get_sink ( ) . get_connector_length ( ) + CONNECTOR_ARROW_HEIGHT NEW_LINE self . x2 , self . y2 = Utils . get_rotated_coordinate ( ( - connector_length , 0 ) , self . get_sink ( ) . get_rotation ( ) ) NEW_LINE # build ▁ the ▁ arrow ENDCOM self . arrow = [ ( 0 , 0 ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , - CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , Utils . get_rotated_coordinate ( ( - CONNECTOR_ARROW_HEIGHT , CONNECTOR_ARROW_BASE / 2 ) , self . get_sink ( ) . get_rotation ( ) ) , ] NEW_LINE self . _update_after_move ( ) NEW_LINE if not self . get_enabled ( ) : self . _arrow_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE elif not self . is_valid ( ) : self . _arrow_color = Colors . CONNECTION_ERROR_COLOR NEW_LINE else : self . _arrow_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE DEDENT
def _update_after_move ( self ) : NEW_LINE INDENT """ Calculate ▁ coordinates . """ NEW_LINE self . clear ( ) # FIXME ▁ do ▁ i ▁ want ▁ this ▁ here ? ENDCOM NEW_LINE # source ▁ connector ENDCOM source = self . get_source ( ) NEW_LINE X , Y = source . get_connector_coordinate ( ) NEW_LINE x1 , y1 = self . x1 + X , self . y1 + Y NEW_LINE self . add_line ( ( x1 , y1 ) , ( X , Y ) ) NEW_LINE # sink ▁ connector ENDCOM sink = self . get_sink ( ) NEW_LINE X , Y = sink . get_connector_coordinate ( ) NEW_LINE x2 , y2 = self . x2 + X , self . y2 + Y NEW_LINE self . add_line ( ( x2 , y2 ) , ( X , Y ) ) NEW_LINE # adjust ▁ arrow ENDCOM self . _arrow = [ ( x + X , y + Y ) for x , y in self . arrow ] NEW_LINE # add ▁ the ▁ horizontal ▁ and ▁ vertical ▁ lines ▁ in ▁ this ▁ connection ENDCOM if abs ( source . get_connector_direction ( ) - sink . get_connector_direction ( ) ) == 180 : NEW_LINE # 2 ▁ possible ▁ point ▁ sets ▁ to ▁ create ▁ a ▁ 3 - line ▁ connector ENDCOM INDENT mid_x , mid_y = ( x1 + x2 ) / 2.0 , ( y1 + y2 ) / 2.0 NEW_LINE points = [ ( ( mid_x , y1 ) , ( mid_x , y2 ) ) , ( ( x1 , mid_y ) , ( x2 , mid_y ) ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ 3 - line ▁ connector ENDCOM p1 , p2 = map ( int , points [ 0 ] [ 0 ] ) , map ( int , points [ 0 ] [ 1 ] ) NEW_LINE self . add_line ( ( x1 , y1 ) , p1 ) NEW_LINE self . add_line ( p1 , p2 ) NEW_LINE self . add_line ( ( x2 , y2 ) , p2 ) NEW_LINE DEDENT else : NEW_LINE # 2 ▁ possible ▁ points ▁ to ▁ create ▁ a ▁ right - angled ▁ connector ENDCOM INDENT points = [ ( x1 , y2 ) , ( x2 , y1 ) ] NEW_LINE # source ▁ connector ▁ - > ▁ points [ 0 ] ▁ should ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ▁ ( if ▁ possible ) ENDCOM if Utils . get_angle_from_coordinates ( ( x1 , y1 ) , points [ 0 ] ) != source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ sink ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ sink ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x2 , y2 ) ) == sink . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # points [ 0 ] ▁ - > ▁ source ▁ connector ▁ should ▁ not ▁ be ▁ in ▁ the ▁ direction ▁ of ▁ source ENDCOM if Utils . get_angle_from_coordinates ( points [ 0 ] , ( x1 , y1 ) ) == source . get_connector_direction ( ) : points . reverse ( ) NEW_LINE # create ▁ right - angled ▁ connector ENDCOM self . add_line ( ( x1 , y1 ) , points [ 0 ] ) NEW_LINE self . add_line ( ( x2 , y2 ) , points [ 0 ] ) NEW_LINE DEDENT DEDENT
def draw ( self , gc , window ) : NEW_LINE INDENT """ STRNEWLINE TABSYMBOL TABSYMBOL Draw ▁ the ▁ connection . STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ gc ▁ the ▁ graphics ▁ context STRNEWLINE TABSYMBOL TABSYMBOL @ param ▁ window ▁ the ▁ gtk ▁ window ▁ to ▁ draw ▁ on STRNEWLINE TABSYMBOL TABSYMBOL """ NEW_LINE sink = self . get_sink ( ) NEW_LINE source = self . get_source ( ) NEW_LINE # check ▁ for ▁ changes ENDCOM if self . _sink_rot != sink . get_rotation ( ) or self . _source_rot != source . get_rotation ( ) : self . create_shapes ( ) NEW_LINE elif self . _sink_coor != sink . get_coordinate ( ) or self . _source_coor != source . get_coordinate ( ) : self . _update_after_move ( ) NEW_LINE # cache ▁ values ENDCOM self . _sink_rot = sink . get_rotation ( ) NEW_LINE self . _source_rot = source . get_rotation ( ) NEW_LINE self . _sink_coor = sink . get_coordinate ( ) NEW_LINE self . _source_coor = source . get_coordinate ( ) NEW_LINE # draw ENDCOM if self . is_highlighted ( ) : border_color = Colors . HIGHLIGHT_COLOR NEW_LINE elif self . get_enabled ( ) : border_color = Colors . CONNECTION_ENABLED_COLOR NEW_LINE else : border_color = Colors . CONNECTION_DISABLED_COLOR NEW_LINE Element . draw ( self , gc , window , bg_color = None , border_color = border_color ) NEW_LINE # draw ▁ arrow ▁ on ▁ sink ▁ port ENDCOM gc . set_foreground ( self . _arrow_color ) NEW_LINE window . draw_polygon ( gc , True , self . _arrow ) NEW_LINE DEDENT
